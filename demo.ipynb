{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0f3b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      2\u001b[39m client = OpenAI()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-5.2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a short bedtime story about a unicorn.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.output_text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\EEC\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:866\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    829\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    830\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    865\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\EEC\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1294\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1285\u001b[39m     warnings.warn(\n\u001b[32m   1286\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1288\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1289\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1290\u001b[39m     )\n\u001b[32m   1291\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1292\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1293\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\EEC\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1067\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1064\u001b[39m             err.response.read()\n\u001b[32m   1066\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1069\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d539f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word ‚Äústrawberry‚Äù contains **3** occurrences of the letter **r**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"openai/gpt-oss-120b:free\",\n",
    "    input=\"How many r's are in the word 'strawberry'?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79897d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many times the letter \"r\" appears in the word \"strawberry,\" let's break it down:\n",
      "\n",
      "The word is: **S T R A W B E R R Y**\n",
      "\n",
      "- The first \"r\" is the **3rd letter**.\n",
      "- The second \"r\" is the **8th letter**.\n",
      "\n",
      "So, the letter \"r\" appears **2 times** in \"strawberry.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    input=\"How many r's are in the word 'strawberry'?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d874e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b:free\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    # temperature=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    # temperature=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"Write a short bedtime story about a unicorn.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71d5ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!‚ÄØArtificial Intelligence (AI) is a branch of computer science that focuses on creating systems capable of performing tasks that normally require human intelligence. These tasks can include:\n",
      "\n",
      "- **Learning** ‚Äì acquiring knowledge from data (e.g., recognizing patterns in images or text).  \n",
      "- **Reasoning** ‚Äì drawing conclusions or making decisions based on rules or evidence.  \n",
      "- **Perception** ‚Äì interpreting sensory input such as vision, sound, or touch.  \n",
      "- **Language Understanding** ‚Äì processing and generating human language (like what I‚Äôm doing right now).  \n",
      "- **Planning & Problem‚Äësolving** ‚Äì figuring out sequences of actions to achieve a goal.\n",
      "\n",
      "### How AI Works\n",
      "1. **Data** ‚Äì AI models are trained on large amounts of data (texts, images, sensor readings, etc.).  \n",
      "2. **Algorithms** ‚Äì Mathematical procedures (e.g., neural networks, decision trees, reinforcement learning) that find patterns in the data.  \n",
      "3. **Models** ‚Äì The result of training; a model can make predictions or generate outputs when given new inputs.  \n",
      "\n",
      "### Types of AI\n",
      "| Category | Description | Example |\n",
      "|----------|-------------|---------|\n",
      "| **Narrow (Weak) AI** | Designed for a specific task. | Voice assistants (Siri, Alexa), image classifiers, recommendation engines. |\n",
      "| **General (Strong) AI** | Hypothetical AI that can understand, learn, and apply knowledge across any domain like a human. | Not yet achieved; a topic of research and debate. |\n",
      "| **Superintelligent AI** | An intelligence far surpassing human capabilities in all areas. | Purely speculative at this point. |\n",
      "\n",
      "### Common Techniques\n",
      "- **Machine Learning (ML)** ‚Äì Algorithms that improve automatically with experience (e.g., linear regression, random forests).  \n",
      "- **Deep Learning** ‚Äì A subset of ML using multi‚Äëlayer neural networks, especially good at image, speech, and language tasks.  \n",
      "- **Reinforcement Learning** ‚Äì Agents learn by interacting with an environment and receiving rewards/punishments (e.g., AlphaGo, robotics).  \n",
      "- **Natural Language Processing (NLP)** ‚Äì Enables computers to understand and generate human language (chatbots, translation).  \n",
      "\n",
      "### Everyday Examples\n",
      "- **Search engines** ranking results based on relevance.  \n",
      "- **Spam filters** that detect unwanted emails.  \n",
      "- **Self‚Äëdriving cars** that perceive surroundings and make driving decisions.  \n",
      "- **Personalized recommendations** on Netflix, Spotify, or Amazon.  \n",
      "\n",
      "### Why AI Matters\n",
      "- **Automation** of repetitive or dangerous tasks.  \n",
      "- **Insights** from massive datasets that humans can‚Äôt manually analyze.  \n",
      "- **New capabilities** such as real‚Äëtime language translation, medical image diagnosis, and creative content generation.  \n",
      "\n",
      "In short, AI is about building machines that can ‚Äúthink‚Äù (in a limited, task‚Äëspecific sense) and act intelligently, helping us solve problems faster, more accurately, or in ways that were previously impossible. If you‚Äôd like to dive deeper into any particular aspect‚Äîlike how neural networks work, ethical considerations, or practical applications‚Äîjust let me know!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "user_input=input(\"Enter the Question: \")\n",
    "\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are an AI Reasearcher\"),\n",
    "    HumanMessage(content=user_input),\n",
    "]\n",
    "llm = ChatOpenAI(\n",
    "    model=\"openai/gpt-oss-120b:free\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0.7)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815d25b",
   "metadata": {},
   "source": [
    "## **Prompt Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71d394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Machine Learning (ML)** is a subfield of artificial intelligence (AI) that focuses on building systems that can learn from data, identify patterns, and make decisions or predictions without being explicitly programmed for each specific task.\\n\\n### Core Idea\\n- **Learning from Data:** Instead of writing explicit rules, you feed a computer algorithm a set of examples (training data). The algorithm discovers the underlying relationships and creates a model.\\n- **Generalization:** The model should perform well not only on the data it has seen but also on new, unseen data.\\n\\n### How It Works (High‚ÄëLevel Steps)\\n\\n| Step | Description |\\n|------|--------------|\\n| **1. Data Collection** | Gather relevant data (images, text, sensor readings, etc.). |\\n| **2. Pre‚Äëprocessing** | Clean, normalize, and possibly transform the data (e.g., feature extraction). |\\n| **3. Choose a Model/Algorithm** | Select a learning algorithm (e.g., linear regression, decision trees, neural networks). |\\n| **4. Training** | Feed the training data to the algorithm; it adjusts internal parameters to minimize error. |\\n| **5. Validation / Tuning** | Evaluate performance on a separate validation set and tweak hyper‚Äëparameters. |\\n| **6. Testing** | Measure final performance on a held‚Äëout test set to estimate real‚Äëworld behavior. |\\n| **7. Deployment** | Integrate the trained model into an application for inference (making predictions). |\\n\\n### Main Categories of Machine Learning\\n\\n| Category | What It Does | Typical Algorithms |\\n|----------|--------------|--------------------|\\n| **Supervised Learning** | Learns a mapping from inputs to known outputs (labels). | Linear regression, logistic regression, support vector machines, random forests, deep neural networks. |\\n| **Unsupervised Learning** | Finds structure in data without explicit labels. | K‚Äëmeans clustering, hierarchical clustering, principal component analysis (PCA), autoencoders. |\\n| **Semi‚ÄëSupervised Learning** | Uses a small amount of labeled data plus a large amount of unlabeled data. | Self‚Äëtraining, graph‚Äëbased methods. |\\n| **Reinforcement Learning** | Learns by interacting with an environment and receiving rewards/punishments. | Q‚Äëlearning, policy gradients, deep Q‚Äënetworks (DQN). |\\n| **Self‚ÄëSupervised Learning** | Generates its own supervisory signal from the raw data (often used in language and vision). | Contrastive learning, masked language modeling (e.g., BERT). |\\n\\n### Common Applications\\n\\n- **Computer Vision:** Image classification, object detection, facial recognition.\\n- **Natural Language Processing (NLP):** Sentiment analysis, machine translation, chatbots.\\n- **Recommendation Systems:** Suggest movies, products, or music based on user behavior.\\n- **Healthcare:** Predict disease risk, analyze medical images, personalize treatment.\\n- **Finance:** Fraud detection, algorithmic trading, credit scoring.\\n- **Autonomous Systems:** Self‚Äëdriving cars, robotics, drones.\\n\\n### Example: Spam Email Filter (Supervised Learning)\\n\\n1. **Data:** A large set of emails labeled as ‚Äúspam‚Äù or ‚Äúnot spam.‚Äù\\n2. **Features:** Word frequencies, presence of certain phrases, sender domain, etc.\\n3. **Algorithm:** Na√Øve Bayes classifier (or a modern deep learning model).\\n4. **Training:** The algorithm learns probabilities that associate features with the ‚Äúspam‚Äù label.\\n5. **Prediction:** When a new email arrives, the model computes the likelihood it‚Äôs spam and flags it accordingly.\\n\\n### Key Concepts & Terminology\\n\\n- **Model:** The mathematical representation learned from data (e.g., a set of weights in a neural network).\\n- **Parameters vs. Hyper‚Äëparameters:**  \\n  - *Parameters* are learned during training (e.g., weights).  \\n  - *Hyper‚Äëparameters* are set before training (e.g., learning rate, number of layers).\\n- **Loss / Cost Function:** Quantifies how far predictions are from true values; the training process aims to minimize it.\\n- **Overfitting:** Model memorizes training data and performs poorly on new data. Mitigated by regularization, dropout, or more data.\\n- **Underfitting:** Model is too simple to capture underlying patterns, leading to high error on both training and test data.\\n- **Cross‚Äëvalidation:** Technique to assess model performance more reliably by rotating training/validation splits.\\n\\n### Getting Started (Practical Steps)\\n\\n1. **Learn the Basics:**  \\n   - Statistics (mean, variance, probability).  \\n   - Linear algebra (vectors, matrices).  \\n   - Calculus (gradients) ‚Äì especially for deep learning.\\n2. **Pick a Programming Language:** Python is the most popular due to libraries like scikit‚Äëlearn, TensorFlow, PyTorch, and pandas.\\n3. **Hands‚ÄëOn Projects:**  \\n   - Kaggle competitions (e.g., Titanic survival prediction).  \\n   - Simple image classification with MNIST dataset.  \\n   - Sentiment analysis on movie reviews.\\n4. **Study Core Algorithms:** Start with linear regression, logistic regression, decision trees, then move to ensemble methods (random forest, XGBoost) and finally neural networks.\\n5. **Read & Follow Tutorials:**  \\n   - ‚ÄúHands‚ÄëOn Machine Learning with Scikit‚ÄëLearn, Keras, and TensorFlow‚Äù (Aur√©lien G√©ron).  \\n   - Andrew Ng‚Äôs Machine Learning and Deep Learning Specializations (Coursera).  \\n   - Fast.ai practical deep‚Äëlearning courses.\\n\\n### TL;DR\\n\\nMachine Learning is a set of techniques that let computers automatically improve at a task by learning patterns from data, rather than following hard‚Äëcoded rules. It powers many modern technologies‚Äîfrom voice assistants to fraud detectors‚Äîby building models that can generalize from past examples to new, unseen situations.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1240, 'prompt_tokens': 73, 'total_tokens': 1313, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 40, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-120b:free', 'system_fingerprint': None, 'id': 'gen-1770099227-xykhv3e3FJiqmVerQyFd', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2222-b6f0-7bb1-85bc-317ed1344a9d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 73, 'output_tokens': 1240, 'total_tokens': 1313, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 40}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt=PromptTemplate.from_template(\"What is {user_input}\")\n",
    "\n",
    "final_prompt=prompt.invoke(input=\"Machine Learning\")\n",
    "\n",
    "llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121642c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Data Science** is an interdisciplinary field that extracts knowledge, insights, and value from data‚Äîboth structured (e.g., tables, databases) and unstructured (e.g., text, images, video). It blends concepts from statistics, computer science, mathematics, and domain‚Äëspecific expertise to turn raw data into actionable information.\\n\\n---\\n\\n## Core Elements\\n\\n| Element | What It Involves | Typical Tools / Techniques |\\n|---------|------------------|-----------------------------|\\n| **Domain Knowledge** | Understanding the business, scientific, or social context of the problem. | Interviews, literature review, subject‚Äëmatter experts. |\\n| **Data Engineering** | Collecting, cleaning, storing, and preparing data for analysis. | SQL, NoSQL, ETL pipelines, Apache Spark, Airflow, cloud storage (AWS S3, GCS). |\\n| **Statistical & Mathematical Foundations** | Modeling uncertainty, inference, hypothesis testing, optimization. | Probability theory, linear algebra, calculus, Bayesian methods. |\\n| **Machine Learning / AI** | Building predictive or descriptive models that learn patterns from data. | Scikit‚Äëlearn, TensorFlow, PyTorch, XGBoost, LightGBM. |\\n| **Data Visualization & Communication** | Translating results into understandable visual and narrative forms. | Matplotlib, Seaborn, Plotly, Tableau, Power BI, D3.js. |\\n| **Software Engineering Practices** | Writing reproducible, maintainable, and scalable code. | Version control (Git), CI/CD, containerization (Docker), testing. |\\n| **Ethics & Governance** | Ensuring responsible use of data (privacy, bias, fairness). | GDPR, HIPAA, model‚Äëcard documentation, bias‚Äëmitigation libraries. |\\n\\n---\\n\\n## Typical Data‚ÄëScience Workflow (CRISP‚ÄëDM / OSEMN)\\n\\n1. **Business Understanding** ‚Äì Define the problem, success metrics, and constraints.  \\n2. **Data Acquisition** ‚Äì Pull data from databases, APIs, sensors, web scraping, or third‚Äëparty sources.  \\n3. **Data Exploration & Cleaning** ‚Äì Summarize, visualize, detect outliers, handle missing values, and transform variables.  \\n4. **Feature Engineering** ‚Äì Create informative variables (e.g., aggregations, embeddings, time‚Äëseries lags).  \\n5. **Modeling** ‚Äì Choose, train, and tune algorithms (regression, classification, clustering, deep learning, etc.).  \\n6. **Evaluation** ‚Äì Use appropriate metrics (accuracy, ROC‚ÄëAUC, RMSE, precision‚Äërecall, etc.) and validation strategies (cross‚Äëvalidation, hold‚Äëout, time‚Äësplit).  \\n7. **Deployment** ‚Äì Serve models via APIs, batch jobs, or embedded in applications; monitor performance.  \\n8. **Communication** ‚Äì Build dashboards, reports, or storytelling presentations for stakeholders.  \\n\\n---\\n\\n## Common Applications\\n\\n| Industry | Example Use‚ÄëCases |\\n|----------|-------------------|\\n| **Finance** | Credit‚Äërisk scoring, fraud detection, algorithmic trading, customer segmentation. |\\n| **Healthcare** | Disease prediction, drug discovery, medical‚Äëimage analysis, patient‚Äëoutcome modeling. |\\n| **Retail & E‚Äëcommerce** | Recommendation engines, demand forecasting, price optimization, churn analysis. |\\n| **Manufacturing** | Predictive maintenance, quality control, supply‚Äëchain optimization. |\\n| **Transportation** | Route optimization, demand‚Äësupply matching (e.g., ridesharing), autonomous‚Äëvehicle perception. |\\n| **Media & Entertainment** | Content recommendation, audience sentiment analysis, ad‚Äëtargeting. |\\n| **Public Sector** | Crime hotspot prediction, traffic flow analysis, policy impact assessment. |\\n\\n---\\n\\n## Popular Tool Stack (2024)\\n\\n| Category | Open‚ÄëSource | Commercial / Cloud |\\n|----------|-------------|--------------------|\\n| **Programming** | Python (pandas, NumPy, SciPy), R, Julia | MATLAB, SAS |\\n| **Data Storage** | PostgreSQL, MySQL, MongoDB, Hadoop HDFS | Snowflake, Amazon Redshift, Google BigQuery |\\n| **Processing** | Apache Spark, Dask, Ray | Databricks, AWS Glue |\\n| **ML Frameworks** | Scikit‚Äëlearn, XGBoost, LightGBM, TensorFlow, PyTorch | Azure ML, Google Vertex AI, Amazon SageMaker |\\n| **Visualization** | Matplotlib, Seaborn, Plotly, Bokeh | Tableau, Power BI, Looker |\\n| **MLOps** | MLflow, Kubeflow, DVC | Azure DevOps, AWS CodePipeline, Google AI Platform Pipelines |\\n| **Collaboration** | JupyterLab, VS Code, Git | GitHub Enterprise, GitLab, Bitbucket |\\n\\n---\\n\\n## Skills & Learning Path\\n\\n1. **Foundations**  \\n   - Statistics & probability (descriptive stats, hypothesis testing, Bayesian basics).  \\n   - Linear algebra & calculus (gradient descent, matrix operations).  \\n   - Programming (Python is the de‚Äëfacto standard; R for statistical work).  \\n\\n2. **Data Handling**  \\n   - SQL for relational data.  \\n   - Data wrangling with pandas / dplyr.  \\n   - Basics of big‚Äëdata tools (Spark, Hadoop).  \\n\\n3. **Machine Learning**  \\n   - Supervised learning (regression, classification).  \\n   - Unsupervised learning (clustering, dimensionality reduction).  \\n   - Model evaluation & validation.  \\n\\n4. **Specializations** (choose based on interest)  \\n   - **Deep Learning** ‚Äì CNNs for images, RNN/Transformers for text/audio.  \\n   - **NLP** ‚Äì Tokenization, embeddings, language models (BERT, GPT).  \\n   - **Time‚ÄëSeries** ‚Äì ARIMA, Prophet, LSTM, forecasting pipelines.  \\n   - **Computer Vision** ‚Äì Object detection, segmentation, vision transformers.  \\n\\n5. **Production & Communication**  \\n   - Building APIs (FastAPI, Flask).  \\n   - Containerization (Docker) & orchestration (Kubernetes).  \\n   - Storytelling with dashboards and clear documentation.  \\n\\n6. **Ethics & Governance**  \\n   - Data privacy laws (GDPR, CCPA).  \\n   - Fairness, accountability, transparency (FAT) frameworks.  \\n\\n---\\n\\n## Career Roles\\n\\n| Role | Typical Responsibilities | Typical Salary (US, 2024) |\\n|------|--------------------------|--------------------------|\\n| **Data Analyst** | Query data, create reports, basic visualizations. | $65‚Äë$85k |\\n| **Data Engineer** | Build pipelines, maintain data warehouses, ensure data quality. | $110‚Äë$150k |\\n| **Machine Learning Engineer** | Deploy and scale ML models, optimize inference latency. | $130‚Äë$180k |\\n| **Data Scientist** | End‚Äëto‚Äëend analytics, model development, business insight generation. | $120‚Äë$170k |\\n| **Research Scientist (AI/ML)** | Advance state‚Äëof‚Äëthe‚Äëart algorithms, publish papers. | $150‚Äë$250k |\\n| **Analytics Manager / Lead** | Guide teams, align projects with strategy, stakeholder communication. | $150‚Äë$210k |\\n\\n*(Salaries vary by region, industry, and experience.)*\\n\\n---\\n\\n## Getting Started ‚Äì A Mini‚ÄëProject Blueprint\\n\\n1. **Problem**: Predict whether a customer will churn in the next month.  \\n2. **Data**: CSV of customer demographics, usage metrics, support tickets.  \\n3. **Steps**  \\n   - Load data with `pandas`; explore with `df.describe()` and histograms.  \\n   - Clean: impute missing values, encode categorical variables (`OneHotEncoder`).  \\n   - Feature engineer: create ‚Äúaverage monthly usage‚Äù, ‚Äúdays since last support ticket‚Äù.  \\n   - Split: `train_test_split` (80/20).  \\n   - Model: train a `RandomForestClassifier`, tune with `GridSearchCV`.  \\n   - Evaluate: compute ROC‚ÄëAUC, confusion matrix, and calibration curve.  \\n   - Deploy: export model with `joblib`, wrap in a FastAPI endpoint, containerize with Docker.  \\n   - Visualize: build a simple Streamlit dashboard showing churn probability for a given customer.  \\n\\nThis end‚Äëto‚Äëend flow illustrates the core competencies of a data scientist.\\n\\n---\\n\\n### TL;DR\\n\\nData Science = **the systematic extraction of actionable insight from data** using a blend of **domain expertise, statistical reasoning, programming, and machine‚Äëlearning techniques**, all while adhering to **ethical and reproducible practices**. It powers modern decision‚Äëmaking across virtually every industry.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1839, 'prompt_tokens': 83, 'total_tokens': 1922, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 52, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-120b:free', 'system_fingerprint': None, 'id': 'gen-1770099849-S5IoOyqAFU5sCA5qN2ZP', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c222c-32d6-73c2-9dcc-206f7ba21d6d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 83, 'output_tokens': 1839, 'total_tokens': 1922, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 52}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.\"),\n",
    "        (\"user\",\"What is {user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_prompt=prompt.invoke(\"Data Science\")\n",
    "llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2cf568",
   "metadata": {},
   "source": [
    "# **Pydantic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e89d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class llm_schema(BaseModel):\n",
    "    topic: str\n",
    "    fact: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cef319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic='AI' fact='AI is the future of technology'\n"
     ]
    }
   ],
   "source": [
    "data=llm_schema(**{\"topic\":\"AI\",\"fact\":\"AI is the future of technology\"})\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfbba102",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=None\n",
    ")\n",
    "new_llm=llm.with_structured_output(llm_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a85d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic='AI' fact=\"Did you know that AI models like me don't have 'dreams'‚Äîbut they *do* have 'hallucinations'? Sometimes, when given ambiguous or incomplete information, AI can confidently generate incorrect or nonsensical details (like fictional facts or made-up sources) as if they were real. It‚Äôs like a creative imagination run wild, but without the fun of waking up from it! üòÑ\"\n"
     ]
    }
   ],
   "source": [
    "response=new_llm.invoke(\"write a fun fact about ai\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd425c5b",
   "metadata": {},
   "source": [
    "## TASK..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7f6bc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found, program continues...\n",
      "content=\"Here's a classic for you:\\n\\n**Why don‚Äôt skeletons fight each other?**\\n*Because they don‚Äôt have the guts!*\\n\\nOr if you prefer something a little more modern:\\n\\n**Why did the scarecrow win an award?**\\n*Because he was outstanding in his field!*\\n\\nWant a different style? Let me know‚Äîdad jokes, puns, dark humor, or something else? üòÑ\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 10, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 1.92e-05, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 1.92e-05, 'upstream_inference_prompt_cost': 2e-06, 'upstream_inference_completions_cost': 1.72e-05}}, 'model_provider': 'openai', 'model_name': 'mistralai/mistral-7b-instruct', 'system_fingerprint': None, 'id': 'gen-1770108779-OTcr00iO7TovnvICZ9tz', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c22b4-7316-7b13-ab9b-6643a6dbe40d-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 10, 'output_tokens': 86, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def validate_openrouter_key():\n",
    "    if not os.getenv(\"OPENROUTER_API_KEY\"):\n",
    "        raise RuntimeError(\"The OPENROUTER_API_KEY is missing\")\n",
    "\n",
    "validate_openrouter_key()\n",
    "\n",
    "print(\"API key found, program continues...\")\n",
    "\n",
    "use_large_model = False  # switch this\n",
    "\n",
    "if use_large_model:\n",
    "    model = \"openai/gpt-oss-120b:free\"\n",
    "else:\n",
    "    model = \"mistralai/mistral-7b-instruct\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Tell me a joke\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
